{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Text Generation\n",
    "In this notebook I use a recurrent deep learning model to generate text data. The model will learn a language model from the works of the German philosopher Nietzsche, translated to English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Corpus:  600901\n"
     ]
    }
   ],
   "source": [
    "## DATA IMPORT\n",
    "path = tf.keras.utils.get_file('nietzsche.txt',\n",
    "                               origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "\n",
    "with open(path) as file:\n",
    "    text = file.read().lower()\n",
    "\n",
    "print('Length of Corpus: ', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preface\n",
      "\n",
      "\n",
      "supposing that truth is a woman--what then? is there not ground\n",
      "for suspecting that all philosophers, in so far as they have been\n",
      "dogmatists, have failed to understand women--that the terrible\n",
      "seriousness and clumsy importunity with which they have usually paid\n",
      "their addresses to truth, have been unskilled and unseemly methods for\n",
      "winning a woman? certainly she has never allowed herself to be won; and\n",
      "at present every kind of dogma stands with sad and discouraged mien--if,\n",
      "indeed, it stands at all! for there are scoffers who maintain that it\n",
      "has fallen, that all dogma lies on the ground--nay more, that it is at\n",
      "its last gasp. but to speak seriously, there are good grounds for hoping\n",
      "that all dogmatizing in philosophy, whatever solemn, whatever conclusive\n",
      "and decided airs it has assumed, may have been only a noble puerilism\n",
      "and tyronism; and probably the time is at hand when it will be once\n",
      "and again understood what has actually sufficed for the basis of such\n",
      "imposing and abso\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace('\\n', '')  #Remove newline chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Sequences:  196969\n",
      "Unique character count:  58\n"
     ]
    }
   ],
   "source": [
    "## VECTORIZE CHARACTER SEQUENCES\n",
    "\n",
    "maxlen = 60  #num chars per sequence\n",
    "step = 3     #sequence sample frequency\n",
    "\n",
    "sentences = []   #stores sequences\n",
    "next_chars = []  #prediction targets\n",
    "\n",
    "for i in range(0, len(text)-maxlen, step):\n",
    "    sentence = text[i:i+maxlen]\n",
    "    sentences.append(sentence)\n",
    "    next_chars.append(text[i+maxlen])\n",
    "\n",
    "print('Num of Sequences: ', len(sentences))\n",
    "\n",
    "chars = sorted(list(set(text)))  #Unique chars\n",
    "print('Unique character count: ', len(chars))\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "# Vectorize input data into shape (num_sequences, maxlen, len(chars))\n",
    "# One-hot encoded scheme of character sequences\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)))\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for j, char in enumerate(sentence):\n",
    "        char_idx = char_indices[char]\n",
    "        x[i,j,char_idx] = 1\n",
    "    y[i,char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 128)               95744     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 58)                7482      \n",
      "=================================================================\n",
      "Total params: 103,226\n",
      "Trainable params: 103,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## DEFINE LSTM MODEL\n",
    "model = models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss='categorical_crossentropy'\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next a function is created to sample a character from the model's predicted probability distribution as a result of the softmax activation. This probability distribution is rescaled by a factor `entropy_factor` which controls the degree of entropy of this distribution. The lower this factor, the more predictable the model becomes when generating the next text character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper function for character sampling\n",
    "def sample(preds, entropy_factor=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.exp( np.log(preds) / entropy_factor ) #entropy rescaling\n",
    "    preds = preds / np.sum(preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¤', '¦', '©', '«', 'ã', '†'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_indices.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch # 1\n",
      "--- Generating text with seed: \" ghts in science. in that the newpsychologist is about to put \"\n",
      "\n",
      "----- entropy factor: 0.2\n",
      "ghts in science. in that the newpsychologist is about to puttent and the self the self and the self the contention and the self the self the sulfer and the such the such and the most the the self and the sulf the self the self the self the man a self the self the self the content of the self the contoth of the such the all the self the self the self the self and the content and the pristion and the simply be a the most be the the self the such and the pris\n",
      "----- entropy factor: 0.5\n",
      "e simply be a the most be the the self the such and the prise the for the the with the considely the simplefiently that should the intestlives which the praser itself the self the many is for the world the scoulds and meth his realing the one a a word prastion of the moral and inter intercestore and the con or the cortion effic or the a the is a philosopher the contuding who ane and or the renefthing the sulf such the been and \"alter and its that the the s\n",
      "----- entropy factor: 1.0\n",
      "ing the sulf such the been and \"alter and its that the the self knof, wi whe his the itmoral, dimself -opraysto manticaliess plapted: has hhangeing enement ormanter for hhich as a ne'k: a of buely, if honatu moran--\"o among course theic in our etsely cand anter bistlisar uponly hesicctim of with reth of , felw geriting a sharcher terinctaplian, with which the monae of liit fight, toto be the pubtac hach en. of knowd mecciaps ow-breth rad bewhich\" them--how\n",
      " epoch # 2\n",
      "\n",
      " epoch # 3\n",
      "\n",
      " epoch # 4\n",
      "\n",
      " epoch # 5\n",
      "\n",
      " epoch # 6\n",
      "\n",
      " epoch # 7\n",
      "\n",
      " epoch # 8\n",
      "\n",
      " epoch # 9\n",
      "\n",
      " epoch # 10\n",
      "\n",
      " epoch # 11\n",
      "\n",
      " epoch # 12\n",
      "\n",
      " epoch # 13\n",
      "\n",
      " epoch # 14\n",
      "\n",
      " epoch # 15\n",
      "\n",
      " epoch # 16\n",
      "\n",
      " epoch # 17\n",
      "\n",
      " epoch # 18\n",
      "\n",
      " epoch # 19\n",
      "\n",
      " epoch # 20\n",
      "--- Generating text with seed: \"  freedom--the metrical constraint,the tyranny of rhyme and r \"\n",
      "\n",
      "----- entropy factor: 0.2\n",
      " freedom--the metrical constraint,the tyranny of rhyme and result of the series of the same and more as it is a soul of the spiritual and the struggle of the state of the series of the series of the struggle of the series of the state of the same possible of the struggle of the same strughing of the series to the series of the same such as a man will be a subject of the spiritual of the struggle of the series and seriousness, and the spiritual of the serie\n",
      "----- entropy factor: 0.5\n",
      "f the series and seriousness, and the spiritual of the series the man wished to the great from the one and learned to do the disciplinious friends and the common a profound are profound for every further and the strange, and to be successful concerning the political de more were not to be all the different the stiment and experience to say to be discovery of one ofthe family of the same own such can be such as the instinct of the delight of feeling of the \n",
      "----- entropy factor: 1.0\n",
      "an be such as the instinct of the delight of feeling of the very forgirturacesthe find in be moral\" with feeling to which the truth; or log-litide such as a dnesser will honour the slumble of beaudeful artimating the cisind. it have assumitism and prejout, byt"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he wayd art along by thinks todamplentions which the seem. to by the foribly lopments abonewords. otherse the decession--notonugual justice of doculousand laking of the \"humility, of equality are flow\n",
      " epoch # 21\n",
      "\n",
      " epoch # 22\n",
      "\n",
      " epoch # 23\n",
      "\n",
      " epoch # 24\n",
      "\n",
      " epoch # 25\n",
      "\n",
      " epoch # 26\n",
      "\n",
      " epoch # 27\n",
      "\n",
      " epoch # 28\n",
      "\n",
      " epoch # 29\n",
      "\n",
      " epoch # 30\n",
      "\n",
      " epoch # 31\n",
      "\n",
      " epoch # 32\n",
      "\n",
      " epoch # 33\n",
      "\n",
      " epoch # 34\n",
      "\n",
      " epoch # 35\n",
      "\n",
      " epoch # 36\n",
      "\n",
      " epoch # 37\n",
      "\n",
      " epoch # 38\n",
      "\n",
      " epoch # 39\n",
      "\n",
      " epoch # 40\n",
      "--- Generating text with seed: \" t of certainty that will and action aresomehow one; he ascri \"\n",
      "\n",
      "----- entropy factor: 0.2\n",
      "t of certainty that will and action aresomehow one; he ascribed the sentically the stall and the more the most and such as the same deceives in the superiority, the soul, not be the sentically the most such as the sentiment in the problem of the same such the sentically the same and self-arright and his same case to the soul, as the sentically the sentically the sentically the same same such as the soul, and the same and one with the sentically the sentica\n",
      "----- entropy factor: 0.5\n",
      "e soul, and the same and one with the sentically the sentically with the last sacrifice of the man is the superiority (we for the consequently such a consequences and the same own belief the moraling of the endowed the supposing of deceives in the very problem of this account of the same facultimate and the \"modernament. a same heart of doubt the compulsions which the end and the nature with the end only superioring of his expression, in the world in the s\n",
      "----- entropy factor: 1.0\n",
      "nd only superioring of his expression, in the world in the survivally woald to mastery a sentence harded breading hisguppins. there pride things that it is upon the criberizgunish fronok, men, thedenus to sulture has dowe's time of accordingty oy an equality, perhaps the enemy fine cuiles and soliture world, and let us superound for scientize pours-higher, twing, they doubtition withdreateriver seek to bonastreamion and course orthe observe theesundust lov\n",
      " epoch # 41\n",
      "\n",
      " epoch # 42\n",
      "\n",
      " epoch # 43\n",
      "\n",
      " epoch # 44\n",
      "\n",
      " epoch # 45\n",
      "\n",
      " epoch # 46\n",
      "\n",
      " epoch # 47\n",
      "\n",
      " epoch # 48\n",
      "\n",
      " epoch # 49\n",
      "\n",
      " epoch # 50\n",
      "\n",
      " epoch # 51\n",
      "\n",
      " epoch # 52\n",
      "\n",
      " epoch # 53\n",
      "\n",
      " epoch # 54\n",
      "\n",
      " epoch # 55\n",
      "\n",
      " epoch # 56\n",
      "\n",
      " epoch # 57\n",
      "\n",
      " epoch # 58\n",
      "\n",
      " epoch # 59\n",
      "\n",
      " epoch # 60\n",
      "--- Generating text with seed: \" ing it. but the way is openfor new acceptations and refineme \"\n",
      "\n",
      "----- entropy factor: 0.2\n",
      "ing it. but the way is openfor new acceptations and refinement of the same the same the same as the sense of the sense of the profound and the soul of the same as the saint is the soul of the same as the sense of the same of the soul of the sense of the soul of the word the same the sense of the soul that it is all the fact that is the sense of the soul and the same of the consequences of the soul of the fact that with the same as the same the profound tha\n",
      "----- entropy factor: 0.5\n",
      " of the fact that with the same as the same the profound that it is not in the same the \"sential expression, the truth it. in the leadge of the desiration and soul, as the states to the freedom\" of the fear of the general desirable the fact that is a philosopher is no linging of the strongest and to be the soul as if the most defected olden the consideration of the \"truth is even that was the instinct that the family to be strangest of the master of the gr\n",
      "----- entropy factor: 1.0\n",
      "inct that the family to be strangest of the master of the greaulustreeund the full instultinf, a loftieter long and the metaphysiate! as to steepen the family to the most frantier, finally as conclusion of the metaphysics. but we more yor men that phated the placriefically, had pain, genires and thisdragitsionome as tunchars of it is theone's mag,tore's inwhich contrary of its german the leavte: through self to dictated the greedement of the most orms cour"
     ]
    }
   ],
   "source": [
    "## TEXT-GENERATION\n",
    "num_epochs = 60\n",
    "batch_size = 128\n",
    "entropy_list = [0.2, 0.5, 1.0]  #Different values to generate text with\n",
    "gen_char_limit = 400  #Number of characters to generate from seed\n",
    "\n",
    "epochs_to_print_txt = [1, 20, 40, 60]\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    print('\\n epoch #', epoch)\n",
    "    model.fit(x, y, batch_size=batch_size, epochs=1, verbose=0)\n",
    "    start_index = random.randint(0, len(text)-maxlen-1)\n",
    "    generated_text = text[start_index : start_index+maxlen]\n",
    "    \n",
    "    if epoch in epochs_to_print_txt:\n",
    "        print('--- Generating text with seed: \"', generated_text, '\"')\n",
    "    \n",
    "        for entropy in entropy_list:\n",
    "            print('\\n----- entropy factor:', entropy)\n",
    "            sys.stdout.write(generated_text)\n",
    "            sys.stdout.flush()\n",
    "            for i in range(gen_char_limit):\n",
    "                #One-hot encoding input sequences\n",
    "                sampled = np.zeros((1, maxlen, len(chars)))\n",
    "                for t, char in enumerate(generated_text):\n",
    "                    sampled[0, t, char_indices[char]] = 1.\n",
    "\n",
    "                #Sample next char from prediction\n",
    "                preds = model.predict(sampled, verbose=0)[0]\n",
    "                #print(preds)\n",
    "                next_index = sample(preds, entropy)\n",
    "                next_char = chars[next_index]\n",
    "\n",
    "                # append new char, keep input size the same\n",
    "                generated_text += next_char\n",
    "                generated_text = generated_text[1:]\n",
    "\n",
    "                sys.stdout.write(next_char)\n",
    "                sys.stdout.flush()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that after the network has converged, low entropy factors result in many repetitive words being generated. At higher entropy values, the model begins outputting a greater variety of words, with some words even being made up in some cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
